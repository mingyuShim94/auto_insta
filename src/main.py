#!/usr/bin/env python3
"""
Instagram ê²Œì‹œë¬¼ í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° - ë©”ì¸ CLI ì¸í„°í˜ì´ìŠ¤
"""

import sys
import argparse
import time
import os
from typing import Optional, List

from .extractor import InstagramTextExtractor
from .utils import (
    format_text_output,
    save_to_file,
    print_error_message,
    print_success_message,
    get_user_confirmation,
)


def parse_arguments() -> argparse.Namespace:
    """ëª…ë ¹ì¤„ ì¸ìˆ˜ íŒŒì‹±"""
    parser = argparse.ArgumentParser(
        description="Instagram ê²Œì‹œë¬¼ ë§í¬ì—ì„œ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.",
        epilog="ì˜ˆì‹œ: python main.py https://www.instagram.com/p/ABC123/",
    )

    parser.add_argument("url", nargs="?", help="Instagram ê²Œì‹œë¬¼ URL")

    parser.add_argument(
        "--metadata",
        "-m",
        action="store_true",
        help="ë©”íƒ€ë°ì´í„° í¬í•¨ (ì‘ì„±ì, ì¢‹ì•„ìš” ìˆ˜, ë‚ ì§œ ë“±)",
    )

    parser.add_argument(
        "--save",
        "-s",
        metavar="FORMAT",
        choices=["txt", "json"],
        help="ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥ (txt ë˜ëŠ” json í˜•ì‹)",
    )

    parser.add_argument(
        "--output", "-o", metavar="FILENAME", help="ì €ì¥í•  íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)"
    )

    parser.add_argument(
        "--quiet", "-q", action="store_true", help="ìµœì†Œí•œì˜ ì¶œë ¥ë§Œ í‘œì‹œ"
    )

    parser.add_argument(
        "--batch-file",
        "-b",
        metavar="FILEPATH",
        help="URL ëª©ë¡ì´ í¬í•¨ëœ íŒŒì¼ ê²½ë¡œ",
    )

    parser.add_argument(
        "--combined-output",
        "-c",
        action="store_true",
        help="ëª¨ë“  ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ í†µí•© íŒŒì¼ë¡œ ì €ì¥",
    )

    parser.add_argument(
        "--delay",
        "-d",
        type=int,
        default=3,
        help="URL ì²˜ë¦¬ ê°„ ëŒ€ê¸°ì‹œê°„ (ì´ˆ, ê¸°ë³¸ê°’: 3ì´ˆ)",
    )

    return parser.parse_args()


def read_urls_from_file(file_path: str) -> List[str]:
    """íŒŒì¼ì—ì„œ URL ëª©ë¡ì„ ì½ì–´ì˜¤ê¸°

    Args:
        file_path (str): URL ëª©ë¡ íŒŒì¼ ê²½ë¡œ

    Returns:
        List[str]: URL ëª©ë¡

    Raises:
        FileNotFoundError: íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš°
        ValueError: íŒŒì¼ í˜•ì‹ì´ ì˜ëª»ëœ ê²½ìš°
    """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        urls = []
        for line_num, line in enumerate(lines, 1):
            line = line.strip()
            # ë¹ˆ ì¤„ì´ë‚˜ ì£¼ì„(#ìœ¼ë¡œ ì‹œì‘) ì œì™¸
            if line and not line.startswith('#'):
                if line.startswith('https://') or line.startswith('http://'):
                    urls.append(line)
                else:
                    print(f"âš ï¸ ë¼ì¸ {line_num}: ìœ íš¨í•˜ì§€ ì•Šì€ URL í˜•ì‹ - {line}")

        if not urls:
            raise ValueError("ìœ íš¨í•œ URLì´ ì—†ìŠµë‹ˆë‹¤.")

        return urls

    except FileNotFoundError:
        raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    except Exception as e:
        raise ValueError(f"íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")


def save_combined_results(results: List[dict], output_format: str = 'txt') -> str:
    """ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ë¥¼ í†µí•© íŒŒì¼ë¡œ ì €ì¥

    Args:
        results (List[dict]): ì²˜ë¦¬ ê²°ê³¼ ëª©ë¡
        output_format (str): ì¶œë ¥ í˜•ì‹ ('txt' ë˜ëŠ” 'json')

    Returns:
        str: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    from datetime import datetime
    from .utils import save_to_file
    import json

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    if output_format == 'txt':
        # í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ í†µí•©
        combined_text = []
        combined_text.append("=" * 80)
        combined_text.append("ğŸ“± Instagram ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼")
        combined_text.append(f"ğŸ“… ì²˜ë¦¬ì¼ì‹œ: {datetime.now().strftime('%Yë…„ %mì›” %dì¼ %H:%M:%S')}")
        combined_text.append(f"ğŸ“Š ì´ ì²˜ë¦¬ ê±´ìˆ˜: {len(results)}ê°œ")
        combined_text.append("=" * 80)
        combined_text.append("")

        for i, result in enumerate(results, 1):
            combined_text.append(f"[{i:02d}] {result['url']}")
            combined_text.append(f"ğŸ‘¤ ì‘ì„±ì: @{result.get('username', 'Unknown')}")
            combined_text.append(f"â¤ï¸ ì¢‹ì•„ìš”: {result.get('likes', 0):,}ê°œ")
            if result.get('date'):
                date_str = result['date'].strftime('%Yë…„ %mì›” %dì¼ %H:%M')
                combined_text.append(f"ğŸ“… ê²Œì‹œì¼: {date_str}")
            combined_text.append("")
            combined_text.append("ğŸ’¬ ë³¸ë¬¸:")
            combined_text.append(result.get('text', '(í…ìŠ¤íŠ¸ ì—†ìŒ)'))
            combined_text.append("")
            combined_text.append("-" * 60)
            combined_text.append("")

        # íŒŒì¼ ì €ì¥
        output_dir = "outputs"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        filename = f"instagram_batch_combined_{timestamp}.txt"
        file_path = os.path.join(output_dir, filename)

        with open(file_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(combined_text))

    elif output_format == 'json':
        # JSON í˜•ì‹ìœ¼ë¡œ í†µí•©
        batch_data = {
            'processed_at': datetime.now().isoformat(),
            'total_count': len(results),
            'results': []
        }

        for result in results:
            json_result = result.copy()
            if 'date' in json_result and json_result['date']:
                json_result['date'] = json_result['date'].isoformat()
            batch_data['results'].append(json_result)

        # íŒŒì¼ ì €ì¥
        output_dir = "outputs"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        filename = f"instagram_batch_combined_{timestamp}.json"
        file_path = os.path.join(output_dir, filename)

        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(batch_data, f, ensure_ascii=False, indent=2)

    return file_path


def process_batch_urls(extractor: InstagramTextExtractor, urls: List[str], args: argparse.Namespace) -> List[dict]:
    """ë°°ì¹˜ë¡œ ì—¬ëŸ¬ URL ì²˜ë¦¬

    Args:
        extractor: Instagram í…ìŠ¤íŠ¸ ì¶”ì¶œê¸°
        urls: ì²˜ë¦¬í•  URL ëª©ë¡
        args: ëª…ë ¹ì¤„ ì¸ìˆ˜

    Returns:
        List[dict]: ì²˜ë¦¬ ì„±ê³µí•œ ê²°ê³¼ ëª©ë¡
    """
    results = []
    failed_urls = []
    total_count = len(urls)

    print(f"ğŸš€ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: ì´ {total_count}ê°œ URL")
    print(f"â±ï¸ URL ê°„ ëŒ€ê¸°ì‹œê°„: {args.delay}ì´ˆ")
    print("=" * 60)

    for i, url in enumerate(urls, 1):
        print(f"\n[{i:02d}/{total_count:02d}] ì²˜ë¦¬ ì¤‘: {url}")

        try:
            # ì²« ë²ˆì§¸ URLì´ ì•„ë‹ˆë©´ ëŒ€ê¸°
            if i > 1:
                print(f"â³ {args.delay}ì´ˆ ëŒ€ê¸° ì¤‘...")
                time.sleep(args.delay)

            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            post_data = extractor.get_post_text(url)
            results.append(post_data)

            # ì„±ê³µ ë©”ì‹œì§€
            username = post_data.get('username', 'Unknown')
            likes = post_data.get('likes', 0)
            print(f"âœ… ì„±ê³µ: @{username} ({likes:,}ê°œ ì¢‹ì•„ìš”)")

            # ê°œë³„ íŒŒì¼ ì €ì¥ (combined-outputì´ ì•„ë‹Œ ê²½ìš°)
            if args.save and not args.combined_output:
                filename = f"batch_{i:02d}_{username}_{int(time.time())}.{args.save}"
                file_path = save_to_file(post_data, filename, args.save)
                print(f"ğŸ’¾ ì €ì¥: {file_path}")

        except Exception as e:
            error_msg = str(e)
            failed_urls.append({'url': url, 'error': error_msg})
            print(f"âŒ ì‹¤íŒ¨: {error_msg}")
            continue

    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š ë°°ì¹˜ ì²˜ë¦¬ ì™„ë£Œ")
    print(f"âœ… ì„±ê³µ: {len(results)}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {len(failed_urls)}ê°œ")

    # ì‹¤íŒ¨í•œ URL ëª©ë¡ ì €ì¥
    if failed_urls:
        print("\nâŒ ì‹¤íŒ¨í•œ URL ëª©ë¡:")
        for failed in failed_urls:
            print(f"   {failed['url']} - {failed['error']}")

        # ì‹¤íŒ¨ ëª©ë¡ì„ íŒŒì¼ë¡œ ì €ì¥
        output_dir = "outputs"
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        timestamp = int(time.time())
        failed_file = os.path.join(output_dir, f"failed_urls_{timestamp}.txt")
        with open(failed_file, 'w', encoding='utf-8') as f:
            f.write("# ì‹¤íŒ¨í•œ Instagram URL ëª©ë¡\\n")
            f.write(f"# ì²˜ë¦¬ì¼ì‹œ: {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\\n")
            for failed in failed_urls:
                f.write(f"{failed['url']}  # ì˜¤ë¥˜: {failed['error']}\\n")
        print(f"ğŸ’¾ ì‹¤íŒ¨ ëª©ë¡ ì €ì¥: {failed_file}")

    return results


def get_url_interactively() -> Optional[str]:
    """ëŒ€í™”í˜•ìœ¼ë¡œ URL ì…ë ¥ë°›ê¸°"""
    print("ğŸ¯ Instagram ê²Œì‹œë¬¼ í…ìŠ¤íŠ¸ ì¶”ì¶œê¸°")
    print("-" * 40)
    print("Instagram ê²Œì‹œë¬¼ ë§í¬ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    print("(ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit' ì…ë ¥)")
    print()

    while True:
        url = input("ğŸ“± Instagram URL: ").strip()

        if url.lower() in ["quit", "exit", "q"]:
            return None

        if url:
            return url

        print("URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")


def process_single_url(
    extractor: InstagramTextExtractor, url: str, args: argparse.Namespace
) -> bool:
    """ë‹¨ì¼ URL ì²˜ë¦¬

    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    try:
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ
        if not args.quiet:
            print("ğŸ“¥ ê²Œì‹œë¬¼ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")

        post_data = extractor.get_post_text(url)

        # ì½˜ì†” ì¶œë ¥
        if not args.quiet:
            print(format_text_output(post_data, show_metadata=args.metadata))
        else:
            # quiet ëª¨ë“œì—ì„œëŠ” ë³¸ë¬¸ë§Œ ì¶œë ¥
            print(post_data.get("text", ""))

        # íŒŒì¼ ì €ì¥
        if args.save:
            filename = None
            if args.output:
                filename = f"{args.output}.{args.save}"

            file_path = save_to_file(post_data, filename, args.save)
            if not args.quiet:
                print_success_message(f"ê²°ê³¼ë¥¼ {file_path}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

        return True

    except ValueError as e:
        print_error_message("url_error", str(e))
        return False
    except PermissionError as e:
        print_error_message("permission_error", str(e))
        return False
    except ConnectionError as e:
        print_error_message("network_error", str(e))
        return False
    except Exception as e:
        print_error_message("general_error", f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
        return False


def interactive_mode():
    """ëŒ€í™”í˜• ëª¨ë“œ"""
    extractor = InstagramTextExtractor()

    while True:
        url = get_url_interactively()
        if url is None:
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì²˜ë¦¬
        args = argparse.Namespace(metadata=True, save=None, output=None, quiet=False)

        success = process_single_url(extractor, url, args)

        if success:
            # íŒŒì¼ ì €ì¥ ì—¬ë¶€ í™•ì¸
            if get_user_confirmation("ğŸ“ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"):
                print("íŒŒì¼ í˜•ì‹ì„ ì„ íƒí•˜ì„¸ìš”:")
                print("1. í…ìŠ¤íŠ¸ íŒŒì¼ (.txt)")
                print("2. JSON íŒŒì¼ (.json)")

                while True:
                    choice = input("ì„ íƒ (1-2): ").strip()
                    if choice == "1":
                        args.save = "txt"
                        break
                    elif choice == "2":
                        args.save = "json"
                        break
                    else:
                        print("1 ë˜ëŠ” 2ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

                # ë‹¤ì‹œ ì²˜ë¦¬ (íŒŒì¼ ì €ì¥ í¬í•¨)
                post_data = extractor.get_post_text(url)
                file_path = save_to_file(post_data, None, args.save)
                print_success_message(f"ê²°ê³¼ë¥¼ {file_path}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

        print("\n" + "=" * 60 + "\n")

        if not get_user_confirmation("ğŸ”„ ë‹¤ë¥¸ ê²Œì‹œë¬¼ì„ ì²˜ë¦¬í•˜ì‹œê² ìŠµë‹ˆê¹Œ?"):
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    args = parse_arguments()

    # ë°°ì¹˜ íŒŒì¼ ì²˜ë¦¬ ëª¨ë“œ
    if args.batch_file:
        try:
            # URL ëª©ë¡ íŒŒì¼ ì½ê¸°
            urls = read_urls_from_file(args.batch_file)
            print(f"ğŸ“‚ íŒŒì¼ì—ì„œ {len(urls)}ê°œ URLì„ ì½ì—ˆìŠµë‹ˆë‹¤: {args.batch_file}")

            # Instagram í…ìŠ¤íŠ¸ ì¶”ì¶œê¸° ìƒì„±
            extractor = InstagramTextExtractor()

            # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
            results = process_batch_urls(extractor, urls, args)

            # í†µí•© ê²°ê³¼ ì €ì¥
            if args.combined_output and results:
                output_format = args.save or 'txt'
                combined_file = save_combined_results(results, output_format)
                print(f"ğŸ“„ í†µí•© ê²°ê³¼ ì €ì¥: {combined_file}")

            # ì„±ê³µë¥ ì— ë”°ë¥¸ ì¢…ë£Œ ì½”ë“œ
            success_rate = len(results) / len(urls) if urls else 0
            exit_code = 0 if success_rate >= 0.5 else 1  # 50% ì´ìƒ ì„±ê³µì‹œ ì •ìƒ ì¢…ë£Œ
            sys.exit(exit_code)

        except (FileNotFoundError, ValueError) as e:
            print(f"âŒ ë°°ì¹˜ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
            sys.exit(1)

    # URLì´ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° ëŒ€í™”í˜• ëª¨ë“œ
    elif not args.url:
        interactive_mode()
        return

    # ëª…ë ¹ì¤„ ëª¨ë“œ (ë‹¨ì¼ URL)
    else:
        extractor = InstagramTextExtractor()
        success = process_single_url(extractor, args.url, args)
        sys.exit(0 if success else 1)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ í”„ë¡œê·¸ë¨ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        sys.exit(1)
